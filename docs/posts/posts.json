[
  {
    "path": "posts/2024-02-03-Confidence/",
    "title": "Confidence, and how to fake it!",
    "description": "Becoming more self confident in academics",
    "author": [
      {
        "name": "Nebbe Al-Moula",
        "url": {}
      }
    ],
    "date": "2024-02-08",
    "categories": [],
    "contents": "\n\n\n\nIn academia, and life in general, having a little bit of confidence can open many doors. Opportunities are often given to those who believe in themselves and put themselves out there. So confidence is useful, great! What do you do when you are not a naturally confident person? In this blog post we will discuss a few tricks to make yourself appear more confident.\nThe three second rule\nWhen doing public speaking, presentations, or when putting yourself out there in general, confidence is of utmost importance. Coming across as confident will make the listeners trust in your words and believe that whatever you have to say is worthwhile. However, many people find these things nerve wrecking. This is why a good friend of mine taught me “the three second rule”. The three second rule basically says that it only takes three seconds of courage to do something that scares you. For example, you only need three seconds of courage to get up and start your presentation, once you are going you probably wont just give up and sit back down. This rule can be used in any situation you are nervous about. These three seconds of courage won’t necessarily make you any less scared or nervous, but it will help you get started. The most difficult part about public speaking or presentations is the moments leading up to it, during this time you can drive yourself crazy with self-doubt and over thinking. The three second rule is meant to override those thoughts momentarily so you can get a good start.\nDelusions of grandeur\nNow that you’ve mustered up your three seconds of courage and you started your talk, how do you exude this confidence physically. To come across as confident your posture, cadence, and body language are crucial. If you fidget, speak to quickly or too softly, stand hunched over, or constantly look down, you will seem nervous. The solution to this is delusion! Imagine yourself as an important TED talk speaker, or a popular celebrity. Ask yourself how that person would carry themselves during a presentation, and imitate that. You can be performative about it. It’s not a potentially embarrassing presentation, it’s a role you are playing and you are an amazing actor. To your listeners every talk you give is equally important, every presentation is your magnum opus and you should treat it as such. Often times we think we are speaking very loudly or that our gestures are too big and crazy, what I’ve learned is that in reality we don’t look as crazy as we think we do. We tend to automatically tone down our movements and voice when we get nervous, this means that to get the desired effect you have to over-exaggerate everything. So even if it feels stupid, use those extravagant hand gestures and speak like you are delivering a monologue.\nIn conclusion, everyone struggles with self-confidence sometimes. However, with a little bit of courage and a healthy amount of delusion confidence and be faked and eventually built. It is important that we remember that no one is confident all of the time about everything, but everyone will notice the effort you put in to build up your confidence.\n\n\n\n",
    "preview": "posts/2024-02-03-Confidence/ConfidenceImage.png",
    "last_modified": "2024-03-08T11:18:14+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-01-02-scicom/",
    "title": "The icing on the cake",
    "description": "Why science communication should be part of everyone's science",
    "author": [
      {
        "name": "Jessica Schaaf",
        "url": {}
      }
    ],
    "date": "2024-01-02",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nThis year I came up with a New Year’s resolution that I can actually keep: more science communication. So let’s get off to a good start with some science communication… on… science communication!\r\nIn my opinion, science communication entails all communication that aims to convey scientific knowledge, for example, to spark interest or to create awareness or enjoyment. Although we as scientists are not the only ones who can communicate science, the general public puts a lot of faith in our communication; even more so than in that of, for example, the government or journalists (e.g., KNAW, 2013; Rutjens et al., 2018). Besides, we are trained to critically evaluate each other’s (and our own) work, to connect different sources of information, and to communicate scientific results in a clear comprehensible manner. I therefore see it as a scientist’s duty to convey what they learn to the general public. Because what is scientific knowledge worth if it doesn’t reach the general public?\r\nHuman beings are curious… also about your work, Polly!\r\nHowever, science communication is easier said than done. For instance, how do you decide what to communicate? I know many people who throw in the towel at this point, people like pessimistic Polly. Polly likes science communication, but mainly when other people do it. She assumes “nobody is interested in her findings” because “her research is so fundamental, nobody will understand and nobody cares“. I used to be like Polly but talking to people changed my perspective. Yes… a simple thing like talking to people outside of your scientific bubble helps! It does so because it helps you translate tough science into normal language. And because it helps you realize that everything that you have learned during your studies is new to the general public. Everything that you and your fellow scientists investigate now even more so. People are generally very curious beings, constantly trying to minimize the uncertainty about the world around them. Help them to do so!\r\nTimes are changing… so take the time, Bart!\r\nI also met many people that don’t take the time for science communication, people like busy Bart. Bart isn’t such a fan of science communication because “there are so many other, more important things to do”. And in a way, he is right. Science usually doesn’t incentivize science communication. However, times are changing! Nowadays, almost all universities have active science communication departments (who can help!), grants often require some sort of translational impact or outreach, large grants exclusively for science communication are now available (e.g., from the Dutch Science Agenda) and fun initiatives are popping up (e.g., the “Hoe?Zo! Show” and “Lil’ Scientist”). And even if you don’t care about these things, I would argue communicating your results to a lay public speeds up the writing of your papers: because of character limits on social media platforms, you will notice it helps you think about the main message and how to convey it as clearly as possible.\r\nGet in touch with your creative side and start simple\r\nThere’s no need to be like pessimistic Polly or busy Bart. Science communication can be for everyone. See it as the icing on the cake. Get in touch with your creative self and think about what you like to do. Do you like to find hidden gems in the paper jungle? Once you find them, write about it on social media platforms like X (generally good to reach academics) or LinkedIn (generally good to reach non-academics such as clinicians and teachers). Are you more of a visual person? Create infographics once you have results (I know from experience participants really appreciate this way of keeping them up to date). Of course you can make it as crazy as you want. Writing blog posts on your personal or lab website, organizing workshops, recoding podcasts, and so on. However, start simple! Even sharing a new paper on social media counts as science communication.\r\nSo stop reading and start communicating!\r\nJessica Schaaf\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-01-02-scicom/cherryoncake.png",
    "last_modified": "2024-03-08T11:18:14+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-10-28-Autoregression-And-Cats/",
    "title": "What does your ex have in common with magic cats?",
    "description": "Autoregression in 2 short stories",
    "author": [
      {
        "name": "Michael Aristodemou",
        "url": {}
      }
    ],
    "date": "2023-10-30",
    "categories": [],
    "contents": "\n\n\n\nStory 1: Autoregression and magic cats\nToday, we are launching cats in the air. But don’t worry, these are magic cats. Or so they say. You see some days ago two cats showed up on our doorstep and told us that they could fall from any distance and remain unscathed. These self-purported magic cats bragged about how they learned a simple transformation that allows them to soften their fall. Instead of falling like normal cats, they fall by half of their current distance from the ground every second. So, if a cat is 2 meters above the ground right now, in 1-second they will be 1-meter above the ground and 0.5 meters in 2 seconds. This will continue until the cats are safely on the ground (if they ever make it, but more on this later). Swayed by the charisma of these magic cats we decided to conduct an experiment. We wanted to know if these cats fall differently by launching them 16 meters in the air! As you can imagine, our proposal was not popular with the ethics committee. To gather more evidence that would ensure the safety of the cats we decided to use simulations. In close collaboration with the magic cats, we operationalized their falling process using a short model:\n\\[\nX_t = \\beta*X_{t-1} + \\epsilon_{t}\n\\]\nTo understand this model and ensure the survival of our cats, we decided to create a simple scenario that allows us to solve this equation. This equation states that a cat’s current height (\\(X_t\\)) is determined by their height at the previous measurement interval (\\(X_{t-1}\\); in this case a second ago) multiplied by their ability to slow their fall (in this case by half, \\(\\beta=0.5\\)). The final piece of this equation (\\(\\epsilon_t\\)) captures any external forces that influence the cat’s current height (imagine spontaneously activated wind turbines that could push the cat higher).\nLet’s suppose we do launch a cat 16 meters up in the air. If they can do as they say, then their falling rate over 3 seconds should look like this (grab some pen and paper and follow along):\n\\[\nX_{t} = \\beta*X_{t-1} + \\epsilon_{t}\n\\]\nWe launch the cat in the air. We observe the cat’s height at 4 intervals: \\(X_{t-3}\\) = height at launch 0s, \\(X_{t-2}\\) = at 1s, \\(X_{t-1}\\) = at 2s, \\(X_t\\) = at 3s. Their height at the first measurement (\\(X_{t-3}\\)) is fully determined by the launch height. That’s 16 meters. You can view this as an external force affecting our cat’s vertical distance from the ground (\\(e_{t-3}\\)).\n\\[\nX_{t-3} = \\epsilon_{t-3}\\\\\nX_{t-3} = 16\n\\]\nDuring subsequent measurements the vertical height of the cat will be defined by its height on the previous measurement interval (\\(X_{t-n}\\)) multiplied by the amount that they can slow their fall (\\(\\beta\\)). For simplicity we will assume there are no other external forces acting upon the cat’s height (i.e. (\\(\\epsilon_{t-n<3}=0\\)). So, height at each trial is purely determined by the prior height (\\(X_{t-n}\\)) and slowing ability (\\(\\beta\\)).\n\\[\nX_{t-2}=\\beta\\ast X_{t-3}+\\epsilon_{t-2}\\\\\nX_{t-2}=0.5\\ast16+0\\\\\nX_{t-2}=8\n\\]\nThe cat’s height at the 1-second mark is 8 meters. Next, we halve that to find its height at the 2-second mark.\n\\[\nX_{t-1}=\\beta\\ast X_{t-2}+\\epsilon_{t-1}\\\\\nX_{t-1}=0.5\\ast8+0\\\\\nX_{t-1}=4\\\\\n\\]\nAfter 2-seconds we have 4 meters.\n\\[\nX_t=\\beta\\ast X_{t-1}+\\epsilon_t\\\\\nX_t=0.5\\ast4+0\\\\\nX_t=2\n\\]\nFinally, after 3 seconds the magic cat should be 2 meters above the ground. If you plot the points from the equations you just solved, the red curve in Figure 2 appears. You can see that any forces that cause the magic cats to leave the ground have an exponentially decaying effect on their height. The steepness of this exponential decay is determined by the size of the autoregression coefficient (i.e., the \\(\\beta\\)). If we increase the \\(\\beta\\) to a greater value (e.g. 0.7), the slope of the exponential decay becomes flatter (see the blue line in Figure 1). This means that our cats will linger in the sky for longer, sometimes even when the initial launch is shorter (e.g. 8 vs 16 meters). As for magic cats, they only exist in principle for now. If one day the ethics committee approves of our proposal, these braggadocious felines may need to put their money where their mouth is.\n\n\n\nFigure 2. The falling rate of cats depends on their autoregression. The red solid line depicts a cat with an autoregression coefficient of 0.5. They halve their falling distance every interval (t-n). The blue solid line shows the falling rate of a cat with a higher autoregressive coefficient (0.7). The blue and red dashed lines show the size of the external force that pushes the cats up at launch\nStory 2: Autoregression and why your ex will be mad at you forever\nAt this point you may be thinking, that’s all nice but I came here to learn things about my ex and how they are like a magic cat. Well then consider a couple that’s about to get into a heated argument: John and Luca. You can follow their story using Figure 3. Currently they are both calm and collected. Let’s say their mood is at its average (mood = 0 in Figure 3). John is more sensitive but does not hang on to his feelings for very long (\\(\\beta=0.2\\)). Luca is pretty much the opposite. Luca’s mood is hard to shake but once he gets upset, he is likely going to stay that way (\\(\\beta=0.6\\)). So, this lovely couple is having a relatively boring interaction, when suddenly John notices a notification on Luca’s phone. It’s his sister, or as he likes to call her, bad news. John experiences a sharp spike in his mood (\\(\\epsilon_{t-5} = 6\\)). A second later, he composes himself. He is (almost) back to average now. Luca notices this unperturbed and asks John what’s the matter. John responds with “nothing”. Luca dislikes this response (\\(\\epsilon_{t-4}=2\\)), so he looks away trying to conceal his frustration. This upsets John (\\(\\epsilon_{t-3}=7.76\\)). He grabs Luca by the shoulders and shouts at him. A shocked expression washes over Luca’s face as he pushes John away and locks himself in his room (\\(\\epsilon_{t-2}=5.28\\)).\n\n\n\nFigure 3. This figure shows the emotional trajectory of a couple throughout an argument. The dashed lines show the size of the external force their mood receives by interacting with each other. The solid dots show their observed mood which includes the influence of any external pushes. The hollow dots show their mood when it is only affected by their autoregressive coefficient\nWhat happens next? We leave this to our model. In the absence of any added shocks (\\(\\epsilon_t\\)) both John and Luca would eventually calm down. Luca much later than John. But the catch is that they would never return to zero in the absence of any perturbations. You see these models assume that perturbations affect a system, be it cat or person, for infinity. But the effect becomes infinitesimally small. This is because if you keep dividing a value by the autoregression coefficient, it will never be zero (unless you do this infinite times). Thus, if they remain unaffected by the external world, our magic cats will never land, Luca and John will never be as cool as when they started, and your ex will be a little mad at you—forever.\nConclusion\nI hope that through stories of cats and exes you were able to build some intuition about autoregressive models. These models can be used to gain insight into dynamics that move us beyond the mean and deviations from it. Different combinations of volatility and autoregression can lead to insightfully different risk profiles. So, next time you sit and ponder the world around you, try to look at things through the lens of an autoregressive model.\nAuthor: Michael Aristodemou\n\n\n\n",
    "preview": "posts/2023-10-28-Autoregression-And-Cats/flyingcat.png",
    "last_modified": "2024-03-08T11:18:14+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-09-07-Lab-meetings/",
    "title": "template",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Nora Jones",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2022-12-08",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2024-03-08T11:18:14+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-11-16-Donders-Open-Science-Day/",
    "title": "Lowering Barriers to Entry: Reflections on the Donders Open Science Day 2022",
    "description": {},
    "author": [
      {
        "name": "Sam Parsons",
        "url": {}
      }
    ],
    "date": "2022-11-16",
    "categories": [],
    "contents": "\nOpen Science is the hip thing right now, confirmed our first speaker of the day, Dirk van Gorp. The Donders Session: Open Science Day certainly reinvigorated my enthusiasm for open science – and not just because it’s where all the cool kids hang out.\nWe (Fleur Zeldenrust, Sam Parsons, Rogier Kievit, and Laura de Nooij) wanted to showcase a wide range of useful tools and researchers’ experiences in Open Science. Seven speakers joined us in person, and remotely, across three broad sessions.\nIn the spirit of Open Science, recordings1 of the presentations and the slides are available here. The talks speak for themselves, but there were some key take-home messages and threads that ran neatly through the day.\n\n\n\nSession 1: “What is open science?”\nThere isn’t a clear answer, with “almost as many definitions as universities” (Dirk van Gorp). It was enlightening to hear about many initiatives happening at the Radboud – some behind-the-scenes, and others much more visible. The current policy initiatives look to help researchers make their work more Findable and Accessible. Dirk asked the audience who was familiar with the central Open Access policy, and only four hands were raised. This became a running theme of the event, there are many more impressive Open Science-related initiatives out there to learn about and benefit from. Making these initiatives and resources more visible is an important goal.\nSession 2: Our speakers introduced a bunch of useful tools\nGonny Kremers covered how to publish your work openly and the routes to open access, including Green (self-archiving), Gold (journal open access), and hybrid. Gonny shared important information for all Netherlands based researchers about Plan S and the Taverne Amendment. Understanding each is integral for all researchers funded by organisations that have signed Plan S, including NWO, ZonMw, and European Commission.\nPadraig Gleeson shared Open Source Brain, a platform for sharing and developing computational models of neural systems in an open and collaborative way. Open Neuroscience data, open models, and simulation tools are powerful, but to maximise their use, we need the computing infrastructure – Open Source Brain provides this. As Padraig said, and was echoed by almost every other speaker, “we want to lower the barrier for participation in science”.\nCaspar van Lissa introduced a Workflow for Open Reproducible Code in Science (WORCS), a tool to “lower the barrier of entry” into reproducible science. WORCS introduces an open and reproducible research workflow from the beginning of a project. It is built into an R package with github integration – which not only helps reproducibility but adds version control too. This has the benefit of making all of the tasks we usually remember at the last minute (share code, prepare data to share) easy and part of the natural workflow of a project.\n\n\n\nSession 3: Experiences of being an open scientist\nEmma Henderson shared her experience of doing only Registered Reports. For a Registered Report, authors submit a Stage 1 manuscript (introduction, methods, data analysis plan) to a journal for review. The manuscript is reviewed and accepted in-principle, before data are collected. Then, after the data are collected and analyses ran, the manuscript is accepted regardless of the results. This exciting format removes many forms of bias from the publication process, chiefly whether manuscripts are accepted based on significant results. The most common worry for students and their supervisors, interested in registered reports, is time. Emma’s response was clearly “I can make this work” – she completed three for her PhD Thesis. More than that, the review times Emma shared made many of us jealous compared to “traditional” peer review timelines.\nStephanie Forkel shared a smorgasbord of principles and practices of Open Science she uses with her collaborators: Use open tools (e.g. human connectome project, FSL, python), Share your data (e.g. neurovault, github, thingiverse, and Stephanie’s personal website), and make manuscripts open access (e.g. medRxiv, bioRxiv, Research Square, and more). In keeping with the spirit of the day, Stephanie discussed taking everyone else along and equitable access with the Neuroscience Alliance (NEURAL). To further discuss, engage, and communicate check out @CNSeminars; there are journal clubs, journal special issues, interviews, neuroimaging tutorials, movies, debates, and more. There are so many ways to get involved and benefit from Open Science that it can be overwhelming. But, don’t feel like you have to do everything – just find something that works for you.\nCoosje Veldkamp is a project manager of the YOUth Cohort Study. The study itself is super impressive, following nearly 4000 Dutch children throughout development from pregnancy into early adulthood. Added to this, YOUth is a trailblazer in Open Science: the data are FAIR (Findable, Accessible, Interoperable, Reusable) to allow other researchers to use them, they are harmonising these data with other large scale projects (including the Consortium on Individual Development). Coosje shared the vital behind-the-scenes innovation that was required to build and maintain this huge open longitudinal cohort. Finally, Coosje shared the sobering note that funding for YOUth will soon run out, which prompted some audience reflection on the importance of longer-term investment in important open science infrastructure projects.\nDiscussion: A day like this would not be complete without audience discussion and participation, and for our virtual attendees’ who doesn’t enjoy a break-out room discussion? Drawing on the Open Science as a buffet metaphor (Christina Bergman; read more here https://www.bps.org.uk/psychologist/bropenscience-broken-science) we discussed our own experiences, the kinds of open practices we want to try next, and the training we would need.\nThe practices that attendees were keen to adopt included sharing their data and code. We discussed sensitive data as a barrier to sharing, and that a viable work-around is to share simulated or synthetic data that share key statistical characteristics with the real data but are entirely anonymous. There were some fears around sharing code; what if my code is too messy? What if someone finds an error? In the end, we agreed that sharing messy code is still better - whether for others or for ourselves in the future - and at least if an error is found it can be corrected. Rounding off the discussion, we agreed that resources or training in code and data sharing would help alleviate some of these fears to help folk adopt more open practices. Perhaps for the next Donders Open Science day!\nAuthor: Sam Parsons\n\nThe recordings of the presentations are not available at the moment, but will be added soon.↩︎\n",
    "preview": {},
    "last_modified": "2024-03-08T11:18:14+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-16-Null-Results-Are-Significant-Too/",
    "title": "Tell your students: Null results are significant too",
    "description": {},
    "author": [
      {
        "name": "Sam Parsons",
        "url": {}
      }
    ],
    "date": "2022-02-16",
    "categories": [],
    "contents": "\nWe all know that null (non-significant)1 results are informative, useful, and not at all a bad thing, right? Right…\nIn an entirely rigorous scientific approach to surveying peoples’ perspective of null results, I turned to statistics memes2. Just like academia, these memes neatly reflect the 5% alpha threshold: p < .05 and it’s publication party time, p > .05 and you cry a little.\n\n\n\nStudents often come face-to-face with their own personal null results towards the end of their research project. Usually the project is worth a good portion of their final grade and they feel the pressure to write a good report. When “good” includes some version of novelty or innovativeness, it’s understandable that they feel the pressure to “find something interesting” (read as: statistically significant) to discuss.\nSo, when the inevitable happens (p > .053), a path to the dark side emerges: Some students feel fear; what if they made a mistake or somehow ruined their study? Others feel anger, all they see are significant p values and supported hypotheses, why are they denied the right? Still more feel their burning hatred of statistics emerge again, born from a litany of frustrations throughout their training (not to mention math anxiety - see this twitter thread). Finally, many students feel suffering: at the loss of their favorite hypothesis, certainly that their training has given them little experience of describing and interpreting null results, and in feeling their “non-significant results give them nothing to write about”4.\nHonestly, I can’t blame them for feeling this way. The prevalence of Questionable Research Practices5 (e.g. Gopalakrishna et al. 2020) and the volume of student projects that “metamorphosize” from dull nulls into pretty supported results (e.g. O’Boyle et al. 2017) showcase that many established researchers embody the same reactions. Instead of focusing on this bleak outlook, we will keep our minds on supporting research students.\n\n\n\nA highly accurate, and well-sampled, representation of researchers’ responses to null results.\nMost supervisors will recognise any of the following from students’ null result papers:\nThe limitations clearly relate to not finding a significant effect. Sometimes the writing is explicit enough to state that fixing these limitations would help find significant effects.\nThey deploy the oft-used “approaching statistical significance”6 to allow them to discuss results through the more familiar lens of significant result. Again, to “have something to write about”.\nThe conclusions read as if nothing has been learned about the relationship between the variables, that the study itself was uninformative. Including the possibility that there is no true effect.\nConversely we found no effect, therefore no effect exists (and perhaps all the previous research was actually a massive false positive).\nI’ve often wondered how we can help our students and mentees. We can - and should - tell our trainees that a result does not have to be significant to be useful, or important, or “right”, and even publishable. But, however strongly we reinforce this, students are faced with overwhelming evidence to the contrary. Their own readings of the literature and every other subtle (or not subtle) message about new and exciting (significant) results we send them usually obliterates the message by the time they’re analyzing their hard collected data.\nHelping students\nInstead of sinking into an academic existential dread, here are two ways I have tried to help students overcome the dark side of null results (Warning: Your mileage may vary).\nFor several students a shallow dive into Bayes Factors7 and equivalence testing helped drastically. These projects included relatively simple models (e.g. in the realms of t-tests, correlations, and multiple regression) so the learning curve was not too steep. Thank you JASP for being an intuitive tool for students with minimal analyses and/or programming skills to run these analyses. My students were able to write that “the evidence favored the null model” instead of “we did not find a significant effect”, which seemed to empower them to “have something to talk about”. More than this, they had much more confidence in their interpretations of the study, even if that interpretation is that no hypothesis was better supported by the data.\nIn other student projects, we took to preregistration. Preregistration does not solve all problems (nor should it be expected to, or discussed as if it does), and much of this particular benefit could be achieved without any formal preregistration process. For us, and in more than one project, preregistration was a useful tool to explore several patterns of potential results and how we might interpret each one. It forced us to better consider the theory driving the study and how this interacted with our hypotheses and planned analyses (also see this nice blogpost for a similar non-preregistration argument). This did not entirely remove the sting when p > .058. But, those students were more capable of discussing the results in reference to the theory they were testing and the report did not read as if the study was worthless or uninformative.\nBroad improvements in the statistical training students undergo would also help. Whole communities have grown to support improving research training, for example a Framework for Open and Reproducible Research Training. But, waiting for the glacial pace of reforming curricula to catch up with our current needs gets old fast. Note, students likely don’t need more stats or more complex stats. Instead, they need more time dedicated to understanding how statistics work and how they can be used to make inferences.\nIn the meantime, I have a rapid-fire round of discussion points that have helped my students get to grips with interpreting nulls and hopefully feeling less hopelessness when they see p > .05[^And that clap of thunder makes three]. In no particular order, we could dedicate more time to; sampling variability and the dance of confidence intervals, meta analyses, what actually is a p value, effect sizes, open science, statistical power, common statistical misconceptions (Greenland et al., 2016), and that we should expect null effects in a line of studies even when the effect does exist (e.g. Lakens & Etz, 2017). Sharing papers reporting null results (maybe you have published your null results too?), gives students something tangible to grapple with other than being barraged by statistical significance. Avoiding valenced and judgemental language about results - “failed replications”, “failed experiments”, results are “negative” or “positive” - may help students feel more comfortable whatever the results. Finally, we can avoid preemptively making students feel they have missed a valuable opportunity by avoiding telling students that we might be able to publish the study “if we find something interesting”.\nConcluding remarks\nMost students have been told that their null results matter too, that null results tell us something. The often repeated phrase goes something like “even null results tell us something”. Often it feels like we are merely paying lip service to an idealized world of research and academic publishing. But, at the risk of sounding preachy, I believe that with consideration and more training we might create a world in which null results are not demonized and avoided, and instead added to the academic record to facilitate the scientific process. More immediately, maybe we can reduce some of our students’ p value anxiety.\nAuthor: Sam Parsons\nResources and links\nLakens, D., & Etz, A. J. (2017). Too true to be bad: When sets of studies with significant and nonsignificant findings are probably true. Social Psychological and Personality Science, 8(8), 875-881.\nGopalakrishna, G., Riet, G., Vink, G. Stoop, I., Wicherts, J., & Bouter, L. (2020). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: a survey among academic researchers in The Netherlands. https://www.nsri2020.nl/\nGreenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European journal of epidemiology, 31(4), 337–350. https://doi.org/10.1007/s10654-016-0149-3\nO’Boyle Jr, E. H., Banks, G. C., & Gonzalez-Mulé, E. (2017). The chrysalis effect: How ugly initial results metamorphosize into beautiful articles. Journal of Management, 43(2), 376-399.\nReferences\nJASP Materials\nJASP Materials\nFramework for Open and Reproducible Research Training (FORRT)\nCyrussamii\nCoursera - Statistical Inferences\n\nSorry, Bayesians, this might not be for you↩︎\nCode for reproducibility check (https://www.google.co.uk/search?q=p+value+memes). You’re welcome, Open Science.↩︎\nCue thunder clap and ominous music↩︎\nAlmost a literal quote from more than one student↩︎\nOr Questionable Reporting Practices, depending on your personal preference↩︎\nFor other amusing examples from the published literature, see https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/↩︎\nSee, Bayesians, I hadn’t forgotten about you↩︎\nCue the second thunder clap↩︎\n",
    "preview": {},
    "last_modified": "2024-03-08T11:18:14+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-01-17-What-Is-Parsimony-Worth/",
    "title": "What is parsimony worth?",
    "description": {},
    "author": [
      {
        "name": "Michael Aristodemou",
        "url": {}
      }
    ],
    "date": "2022-01-17",
    "categories": [],
    "contents": "\n\n\n\nIn the early 14th century, an English philosopher known as William of Ockham spoke thus: “pluralitas non est ponenda sine necessitate.” Centuries later the credo entities should not be multiplied without necessity has grown to be a universal principle, known as the principle of parsimony, which systematically biases decision making across the vast and varied scientific landscape. My introduction to this principle came during a statistics class when a senior student advised me that if I mention parsimony the department statisticians will do a little dance and award me an entire point on my assignment! Considering my main objective in life was to inflate my GPA, parsimony held a clear value. I’ve since graduated and parsimony has lost its point awarding abilities. Disappointingly, it also seems to have little effect on my supervisor’s dance tendencies. So, if parsimony cannot promote my personal goals, what is parsimony worth?\nParsimony in knowledge discovery\nThe definition of parsimony is by itself non-contentious to anyone who isn’t an avid supporter of redundancy. It also isn’t useful given that its value is context dependent. My interest lies in the domain of knowledge discovery and therefore this is the context in which parsimony will be evaluated. Let’s break down the definition and embed it into context: entities should not be multiplied without necessity. Our ultimate goal is to justify the should not part, that is to identify the utility of simplicity. To do this we first need to define the necessity. For without a target, we cannot judge when the “multiplication of entities” has to cease. Say we want to explain why people with sleep problems also experience fatigue and irritability. After we search for possible explanations, we want to select one—the best one ideally. So we need to compare our explanations, which means we need to transform them into something we can compare in terms of both accuracy and simplicity. One way to do this, is to express our theories as models and use some quantitative metric that reflects the extent to which they fit with our observations (e.g. the bayesian information criterion). We can call this model fit. Drawing from our example we can manufacture two quick-and-dirty theories: a) reciprocal causal associations between all three symptoms explain their co-occurrence; or, more “simply” b) a fourth variable (e.g., depression) causes all of them, which is why they co-occur. These explanations result in two models with different numbers of parameters. We can use the number of parameters needed to formalize an explanation to approximate its simplicity. Thus, we redefine our entities as the number of parameters needed to specify a given explanation. In the case that our models have the same fit, parsimony would dictate that we choose the simpler of the two—the more parsimonious model. Indeed, many metrics of model fit have an inbuilt penalty for the number of parameters a model has, making model fit the product of a trade-off between complexity and fit to the data1. The principle of parsimony can now be rephrased as: the number of parameters should not be multiplied further than is necessary to improve model fit. This brings us to the crux of the matter—why is this a good idea?\n\n\n\nFigure 1. Schematic of two example models one complex (Model A) and one simple (Model B)\nParsimony as bias\nIdeally, we want a model that fits both to our current observations but also fits well to independent samples. Otherwise, we run the risk of a model that fits tightly to random fluctuations in our data outperforming a model that better approximates the process of interest. This is commonly known as overfitting and is problematic since most real-world data reflects both the process of interest and sample-specific noise. To mitigate overfitting one can look at the generalization error, which indicates how well a model performs in a previously unseen sample. The rationale being that if a model performs well on a given dataset because it fits well to the sample-specific noise, then it should do poorly when fitted to another sample. While a model that fits well to the process of interest should fit well to all samples that appropriately measure that process. A common justification for choosing the most parsimonious model is that it will always minimize generalization error. Which brings us to a popular definition of parsimony: the simpler of two models with equal fit on a given dataset, will fit better on unseen datasets. This statement when taken literally is false. The falsity of this statement follows from David Wolpert’s “no free lunch” theorem2. What the “no free lunch” theorem shows is that for any pair of models there are as many domains where the simpler model is preferable as there are domains where the more complex model is preferable. This essentially invalidates the universality of simplicity as a guiding tool for model selection—in fact for any two models A and B there are as many domains where model A has lower generalization error as there are domains where this is true for model B. The more interesting question, however, isn’t whether parsimony guarantees lower generalization error. What is practically interesting is whether the use of parsimony will lead to lower generalization error in most (or all) applied situations. Domingos follows this precise question in an extensive review of empirical circumstances that contradict this weaker justification for parsimony3. Specifically, he shows that within the domain of machine learning simpler models often lead to higher generalization error. Therefore, both empirically and mathematically the claim that parsimony leads to lower generalization error is found wanting.\nSimplicity and comprehensibility\nSo what if parsimony doesn’t buy us more accurate predictions? Arguably a worthwhile cost if our main aim is to understand the world and simpler models are easier to comprehend. But what makes a model more comprehensible? In 2006, van der Maas and colleagues, debuted their theoretical alternative to the dominant g-factor model that presented a single entity as the causal driver of intelligence—much like our fictitious model B (Figure 1). The mutualism model, as van der Maas termed it, is much more complex in terms of parameters than the g-factor model and fits just as well to cross-sectional observations. If we use comprehensibility as a tie-breaker we should be safe betting on the more parsimonious model. Not so fast. Simplicity in terms of the effective number of parameters needed to specify the g-factor model does not reflect its comprehensibility. As van der Maas argues, the mutualism model certainly can multiply the number of parameters, but the g-factor model conjures up “a rather mysterious” hidden variable4. The same can be said for our toy models. Model B buys its simplicity by manufacturing an entirely new, arguably opaque entity, while model A presents a more complex mechanism that nevertheless is easier to comprehend. In other words, we can better intuit how sleeplessness might make one tired and therefore irritable, while it is harder to parse what this depression variable actually is and how it brings symptoms to be. It seems that parsimony also fails to guarantee superior comprehensibility in some domains.\nParsimony in model search\nIt seems not even parsimony suffices as a fast-and-hard rule that we can generously apply to any domain of science. But there is one domain where parsimony may still be unequivocally welcome. This is the domain of model search. Blumer showed mathematically that the more models we test on our data, the greater the chance that the best fitting model will fit poorly on other samples5. This is essentially multiple testing in model search and reflects the fact that testing more models increases the probability that we find a good fitting model purely by chance.\nDomingos presents an accessible overview of the mathematical argumentation in his review. It goes something like this. Let’s say that the generalization error of a hypothesis is greater than ε. From this it follows that the probability that our hypothesis is correct on x number of independent samples is smaller than (1 — ε)x[^ refers to the power of, e.g. 2^2 = 4. Our cutting-edge editor does not have superscript functionality.]. If we consider n number of hypotheses then the probability that at least one of them is correct in all x independent samples is n(1 — ε)^x. If we substitute this with real numbers, we can see that the probability of at least one of our hypotheses being correct increases with the number of hypotheses considered. That is 2(1 — 4)^2 is 18, which is smaller than 4(1 — 4)^2 which is 36. In a nutshell6, “if we select a sufficiently small set of models prior to looking at the data, and by good fortune one of those models closely agrees with the data, we can be confident that it will also do well on future data.7” Hence, multiple testing provides a safe-haven for the historic concept of parsimony, but veers from the traditional interpretation of parsimony as it pertains to the assumptions within an explanation.\nGoodbye parsimony\nThroughout my reading for this blog, I had to bury my naive belief in the powers of parsimony. That’s strike two. Now I will be forced to constrain my models in another way. Through the grind of gaining domain knowledge and thoughtfully integrating it into the a priori specification of my models. This currently seems like the only effective recourse to reduce the number of models tested and improve comprehensibility. Thanks for the points parsimony, you’ve gotten me this far…\nAuthor: Michael Aristodemou\n\nThis can lead to situations where parsimony leads us to choose the simpler model with worse fit to the data. Meaning parsimony is not just a tie-breaker.↩︎\nWolpert, D. H. (1996). The lack of a priori distinctions between learning algorithms. Neural computation, 8(7), 1341-1390.↩︎\nWolpert, D. H. (1996). The lack of a priori distinctions between learning algorithms. Neural computation, 8(7), 1341-1390.↩︎\nVan Der Maas, H. L., Dolan, C. V., Grasman, R. P., Wicherts, J. M., Huizenga, H. M., & Raijmakers, M. E. (2006). A dynamical model of general intelligence: the positive manifold of intelligence by mutualism. Psychological review, 113(4), 842.↩︎\nBlumer, A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. K. (1987). Occam’s razor. Information Processing Letters, 24, 377(380).↩︎\nWolpert, D. H. (1996). The lack of a priori distinctions between learning algorithms. Neural computation, 8(7), 1341-1390.↩︎\nWolpert, D. H. (1996). The lack of a priori distinctions between learning algorithms. Neural computation, 8(7), 1341-1390.↩︎\n",
    "preview": "posts/2022-01-17-What-Is-Parsimony-Worth/Overfitting_Michael.jpg",
    "last_modified": "2024-03-08T11:18:14+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-29-Working-from-home/",
    "title": "Working from home or living at work?",
    "description": {},
    "author": [
      {
        "name": "Rogier Kievit",
        "url": {}
      }
    ],
    "date": "2021-11-29",
    "categories": [],
    "contents": "\n\n\n\nFriday March 6 2020 was the last day I went to my former workplace in Cambridge, UK. As we have a child who is especially vulnerable to viral illness, we decided, well before it was ‘en vogue’, to stay at home. We received rather ominous letters about us not being allowed to leave the house at all – shortly followed by more reassuring letters that ‘opening a window was allowed’.\nWhat many hoped would be a brief period of atypical working arrangement soon stretched to something closer to two years, and is sadly far from over. Never before have our daily work habits changed so fundamentally in such a short period of time, and the same is true for scientists. Conferences with thousands of participants became completely virtual. Lectures were commonly characterized by vast, silent plains of black squares. One is perhaps best off assuming the silence reflects a breathlessly listening audience. In the entire first year in my new post at the Donders institute I was only able to work in person a handful of times – the rest meant (re)starting a new lab in a new country from the kitchen table (not to mention buying a new house through videochat from a different country – but that’s another story). Although, unfortunately, the pandemic is far from over, we can certainly take stock of the many and rapid changes, and reflect on some of the lessons learned.\nThe Bad1\nThe challenges were, and are, many. For instance, working from home with (young) children is often almost impossible - the combination of acting as a teacher at home and at the same time juggling work responsibilities is, to put it mildly, not ideal. This is especially true for the most exciting parts of our work that demand deep thinking and reflection – Something not particularly compatible with simultaneously assisting in the construction of ambitious cardboard castles, tending to snail collections and home ‘baking’. Of course, the challenges for scientists living alone, especially those away from their home or country of origin, are distinct, but no less challenging.\nScientifically, one of the key drawbacks is the lack of casual, unplanned conversations at the coffee machine. These informal contacts prove not only essential as a ‘social glue’, but also as the origin of many new ideas, contacts and collaborations. As good as Zoom and team meetings have become in terms of the core business of sharing talks and slides, they generally fail at the hard-to-explain intellectual chemistry that arises from serendipitous in-person encounters. This is especially problematic for early career researchers, who build up their social and academic networks through these chance encounters. We try our best to replicate such encounters online, but the best we can do is to approximate them – or to hope to develop new strategies to foster them.\nAlthough the reduction of commuting time entails the clear benefit of ‘more hours in the day’, it comes with other, more psychological challenges. When I drop off my daughter in the morning and am working from home, I can be behind my desk a minute later. This sometimes whiplash inducing switch between parenting and work mode is something that takes time to master. A related challenge exists at the other end of the day – When does working from home turn to living at work? It can be overly tempting to continue working at that same kitchen table during dinner preparation, and/or well into late hours (recent research has shown workdays up to 2 hours longer for those working from home ). For long term maintenance of high level ‘deep work’ it is crucial we find rituals that allow a clear(er) division of work and free time, so that we work from home rather, than live at work, in ways sustainable in the long term. We’ve found some value in the advice and strategies in Cal Newport’s ‘Deep Work’, but many other approaches exist.\nThe Ugly\nUndoubtedly one of the ‘ugliest’ features of this pandemic is that it amplifies pre-existing inequities. Several analyses have demonstrated that the adverse consequences for scientific productivity have been especially pronounced for, among others, working parents, especially mothers, of young children2 and/or people of colour right at a career point where the proverbial pipeline is at its leakiest. As a field, we have to try our very best to consider the differential impact of these challenges at any opportunity we have, to try to adjust for the pronounced pandemic disparities.\nThe Good\nThere are, of course, also positive things to come out of our changed work habits. The ability to work remotely and flexibly, requested by people with disabilities of various kinds for decades, turned out to be quite possible once it was needed by a sufficiently large enough group of people. The decrease in commute time means that an efficient day working at home can simultaneously be more productive for work and family/leisure time – a potential win-win. And as challenging as working from home with homeschooling children has been and continues to be, it is also undoubtedly wonderful to be around them (even) more. Personally, I’ve embraced the two most cliched lockdown activities: Learning how to bake sourdough and running further than ever before, both of which are here to stay.\nAnother benefit is that it has become more commonplace to invite speakers from all over the world to small and large gatherings, bringing greater diversity in backgrounds and topics. Since last year we regularly invite the authors of papers in our journal clubs to join part or all of the conversation, hugely enriching the depth of our reading and understanding.\nHybrid and online working have become almost (but not quite) seamless, and meetings that should be zoom calls often are. I think back with some amazement and no real nostalgia at certain meetings where 20 very busy people would commute to a single location, for only 2-3 central people to speak the entire time. Similarly, the realisation that the cost in terms of CO2 and time away from loved ones for conferences at the very least means we should substantially decrease the frequency of academic activities that involve long distance travel3. In theory, this will ultimately allow a more diversified set of conferences where you can attend the majority hybrid or online, yet benefit from the very real added value of in person conferences for a subset. An added benefit of the virtual conference format is that the chat Q&A can be a great leveler - I have noticed that conference questions in chat format often come from a more diverse, more early career scientists, and are often all the more insightful, knowledgeable and creative for it.\nHow we’re trying to make it work\nAt the Donders institute, we are actively trying to learn from the recent past to improve the present as well as the more distant future. Many research groups and scientists from all backgrounds and seniorities have tried out a vast array of creative solutions – Zoom tea breaks, shut up and write sessions, gathertowns, lab walks and elaborate games, and share what works and what doesn’t. One thing my lab has initiated since the more recent tightening of restrictions has been the early morning scrum/rollcall/huddle4: Very brief (5 minute) meetings where everyone outlines their plans and we get to see everyone’s face on a more regular basis. Not only is it nice to see everyone in 2D, if not in reality, but voicing your plans for the day out loud has a surprisingly large beneficial effect on one’s productivity. Similarly, it took a while for me to be convinced of the benefits of Slack, but now that it has become fully integrated it is the virtual heart of the lab – Quick chats and meetings, a steady stream of interesting papers and resources, and attempts to decipher Dutch customs, including stroopwafel etiquette, in our #undutchables channel has become an indispensable part of the lab. Of course, all of the above is from my narrow and rather specific set of circumstances – I’d love to hear from you about challenges I have overlooked, as well as strategies that have worked well (or failed spectacularly).\nThe motto of my former Cambridge College (Fitzwilliam College) is ‘The best of the old and the new’. As we navigate our way through ebbing and flowing Covid waves towards a future version of academic work, I can only hope we take this motto to heart. Revive what we miss whenever possible, and embrace the new opportunities that arise.\nAuthor: Rogier Kievit\n\nThis blogpost is about the consequences of the pandemic for (academic) work, not the pandemic itself, but of course the single largest consequence of the pandemic is direct: (severe) illness and death for many, heartbreak for family, and exhaustion and burnout for care workers.↩︎\nhttps://www.nap.edu/catalog/26061/the-impact-of-covid-19-on-the-careers-of-women-in-academic-sciences-engineering-and-medicine & https://www.nature.com/articles/d41586-021-03045-w↩︎\ne.g. see https://academicflyingblog.wordpress.com/↩︎\nPlease select your least favourite term.↩︎\n",
    "preview": "posts/2021-11-29-Working-from-home/lockdown_Rogier.jpg",
    "last_modified": "2024-03-08T11:18:14+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-14-I-Am-Quant/",
    "title": "I am Quant (and so can you!): Seriously",
    "description": {},
    "author": [
      {
        "name": "Ethan McCormick",
        "url": {}
      }
    ],
    "date": "2021-10-14",
    "categories": [],
    "contents": "\n\n\n\nI’m sure that I am not the only one who has sat in many a conference hall (imagine back through the mists of times to those days), listening to talks and wondering “How am I ever going to be that smart/knowledgeable about [insert just about anything here]?”. As a first-year graduate student, it is perhaps unsurprising that I would feel that way. I had many years ahead of me to gain the knowledge and skills that those speakers had. All those years later, and now I’m officially “Dr. McCormick”, even though only one person ever calls me that (more on him later). However, that feeling doesn’t just go away. I regularly see a talk or read a new paper/preprint and think “Well damn, when am I going to have time to learn this?”. This has especially been true as I have attempted to pivot my research program from one aimed at addressing substantive questions regarding the brain-based changes that driving learning to one focused on studying and developing the quantitative methods we use to understand change over time (i.e., longitudinal models). I am hardly the only one who has felt the lure of advanced methods from more substantive research fields. I came of age in research during a time with a much greater focus on rigorous methods, open science, and reproducibility/replication. Many researchers in my cohort are motivated like never before to incorporate more rigorous methods from statistics and data science into their own work. However, many also find these methods intimidating. After all, how do I know that I’m using them correctly? I have been incredibly fortunate along the way to have had amazing mentors and a bit of luck in learning new methods. Here I will lay out some tips and tricks I have picked up along the way. So, if you are hoping to transition in a major way to quantitative methods, or just hoping to get better estimates for your research questions, hopefully these can help you on your way.\nTake a Course\nI know that in the age of the internet, we are all supposed to be DIYing it towards ultimate knowledge and expertise in whatever subject we take up. I have been able to use online resources to refine skills, or dive into advanced subjects, but I am not made of stern enough stuff to learn structural equation models by my little lonesome at night at my computer reading Bollen, 1989 (although I do recommend that book in the highest terms). Some sort of structured course is incredibly valuable for getting the basics under your belt, which you can then build on independently later. Of course, needing to take a formal course might be a real impediment (especially if they cost money) since not everyone is a graduate student in a quant-heavy institution. Here, some sort of online course or video series may be a great alternative, but the key is to structure it like a course, where you have periodic checks of your understanding and a committed time. Unfortunately, my intention to learn computational modeling in the evenings wasn’t successful until I registered for a course and was expected to show up every week. One free resource people might consider is the podcast Quantitude, where two quantitative faculty talk about a range of topics. It’s not systematic like a course would be, but it’s an amazing resource for those hoping to learn more about specific topics in a fun way.\nFind a Quantitative Person to Pester\nThis is only said partly in jest. When I took quant courses at UNC Chapel Hill, I frequently wanted to chase down offhanded comments by the professors. After a couple weeks of gathering my courage, I set up a meeting with them and basically came with a list of questions. This felt incredibly presumptuous and like I was wasting their time at first, but ultimately, I got more out of those conversations than I will ever be able to count. Not only did I learn more than I would have otherwise about the methods I use every day in my own research then, but those conversations also became the ideas behind manuscripts I am writing now. Like anyone, quant people love to talk about their research with an interested student, and they probably get to do it less often than others. I can’t promise that every quantitative methodologist is as lovely as the ones I have known, and time constraints are real, but you’d be surprised how many of them do want to be pestered by interested students looking to dive into advanced methods past the basic coursework.\nAsk Questions…so many questions\nThis is something I have to remind myself of even now. There is a lot of pressure to appear like you understand something (we’ve all been and seen the nodding heads in class), but there are so many things to know and the best way to accumulate them is to constantly be asking questions when you don’t understand. This also applies to professional development. I came to quant relatively late in my graduate training, but once I developed some relationships with quantitative faculty in my department, I started asking questions like “Do you think this would be a good idea for a paper?” and “Would you be willing to write a training grant with me?” I have found that the people in my career have been incredibly generous with their time and energy.\nThere is No Secret Sauce\nIf anything can be learned from my career trajectory, it’s that there is no hidden secret to getting into quantitative methods. You don’t need to be a math savant (I’m certainly not) and the new generation of methodologists is shaking off the remnants of the “old boys” club culture that was prevalent in prior decades, although much work remains to be done in that direction. Basically, I had the great fortune to study at UNC Chapel Hill with faculty like Ken Bollen, and Dan Bauer, and Patrick Curran. I was excited by what I was learning and so started to haunt the offices of Dan and Patrick. This has not only led to great mentor relationships with great researchers, but also a considerable shift in my program of research. Now instead of being the student, I help run courses and workshops in quantitative methods. If I can do it, so can you. Welcome to the quant side, we have cookies!\nAuthor: Ethan McCormick\n\n\n\n",
    "preview": "posts/2021-10-14-I-Am-Quant/Quant_Ethan.jpg",
    "last_modified": "2024-03-08T11:18:14+01:00",
    "input_file": {}
  }
]
